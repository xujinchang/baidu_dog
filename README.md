# baidu_dog
A method for baidu  dog recognition
# 数据预处理

训练的图片来自三部分,一是官方提供的原始图片,一是使用RFCN检测框架检测的框,还有一个是使用ssd检测框架检测的框.针对检测的框的选取,我们使用每张图片的得分最高的框.
在训练的时候,使用caffe的data层,使用了一些翻转,随机crop,旋转等数据增强的操作.

# 训练网络框架

针对训练网络结构的选取,我们尝试了在ImageNet物体识别好的网络进行微调,其中选取了resnext50(尝试不同的尺度,crop_size=256,320,384),resnext101(crop_size=256,320),dpn92,resnet269,inception resnet v2 和inception v3,v4,最终对这几个网络模型预测的结果进行加权做为最终的结果.

# 实验的详细参数

使用的预训练模型都是基于caffe的模型,一开始固定前面卷积层的学习率,训练最后的fc层和fc层之前的bottleneck,带有bn层的将use_global_status 设为true,一开始的learning_rate 设为1e-4,为了便于挑选模型,训练的时候每隔500轮存一次模型,然后在val集上测试,一旦发现测试结果不好了,就停止训练,之后将所有卷积层的学习率设为1,fc层和fc层之前的bottleneck层的学习率设为10,仍然是每隔500轮存一次,测试在val集上的准确率,挑选模型,每个模型训练2到3个epoch,具体每个模型的配置都在prototxt里面列出来了.

# 其他的一些尝试

将所有模型的fc层之前的bottleneck层的feture 提出来,concat 到一起,使用linear SVM训练分类器,效果没有直接对模型的结果调权重好.
细粒度模型,使用了Bilinear CNNs for Fine-grained Visual Recognition 这篇论文提出的方法,基网络是使用的vgg19,使用的matconvnet的框架,在训完bcnn的基础上,提取feature,使用vlfeat中的svm训练one vs rest 策略,一共训练97次SVM 分类器,最终的测试线上结果也没有之前的调权重的高,所以最终结果也没有用到.

# 实验总结:

关于训练图片的选取,一开始是使用的ssd检测框架,之后看到一些技巧是增大训练样本的数量,所以后来又引入了RFCN的检测框,这两个框一起使用加上原始图片,相当于训练样本扩大了3倍,而且使用检测框的图片会去掉较多的背景噪声,也有助于网络的训练.
关于图片的尺寸,这个也做过几次实验,发现尺寸大一些的图片,训练效果也好一些,因为同样的物体,尺寸大意味着卷积的感受野大,能学到更加丰富的内容.

关于模型的微调,一开始并不是固定卷积层的学习率,而是所有层都一起训练学习,这样造成的结果就是模型训起来特别不容易收敛,而且训练时间较长,浪费了许多时间.之后,看到一些经验是先固定前面的卷积层,只训练全连接层,待网络收敛,再重新学习前面卷积层的参数,这样使得网络训练起来收敛很快而且准确率也比之前那样训练提高的多1到2个点.
关于测试,测试的时候,同一张图片过同一个模型经过翻转和不翻转的两种操作,将得到的softmax的概率相加,之所以这么做的原因也是基于数据增强的原因,做了一次翻转相当于数据量增加两倍,而且将每个图片的概率相加的结果再做一次预测,比只使用一个图片的预测结果要好一些.

关于模型的融合,模型的融合是在单模型都训练到一个很高的情形下,再去融合的,基于单模型在线上的准确率,准确率高的权重大一些这个原则,后期对权重进行调整.这时候也用过训练模型权重的方法,训一个全连接层,但是得出来的权重在线上的结果并没有我们手动调的高,所以这个权重的调整也占了一大多数时间.

总之,感谢举办方提供这个比赛的机会,我们从中收获了远不止这些东西,除了知识技能方面的提高,对深度学习,机器学习,数据预处理,特征工程,模型融合的理解更加深刻,同时还能够提高团队合作,共同攻克问题的能力,同大家在一个公平公正的平台上竞争,感谢百度为我们提供这个平台.

